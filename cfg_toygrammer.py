# -*- coding: utf-8 -*-
"""cfg_toygrammer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xjljZBoeunirBZA0a0lHfEfjszc40ER7
"""

# Install / imports

!pip install --quiet nltk pandas matplotlib networkx pillow ipywidgets

import os, time, math
import pandas as pd
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')
from nltk import CFG
from nltk.parse import ChartParser
from nltk.tree import Tree
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
from IPython.display import display, Markdown, clear_output

nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)


# Inline tree plotting utility

def _assign_positions(nltk_tree):
    counter = {'id': 0}
    positions = {}
    labels = {}
    edges = []
    leaf_x = {'val': 0}

    def traverse(node, depth=0):
        nid = counter['id']; counter['id'] += 1
        if isinstance(node, Tree):
            labels[nid] = node.label()
            child_ids = []
            for ch in node:
                cid = traverse(ch, depth+1)
                child_ids.append(cid)
            xs = [positions[c][0] for c in child_ids] if child_ids else [leaf_x['val']]
            x = sum(xs)/len(xs)
            positions[nid] = (x, -depth)
            for c in child_ids:
                edges.append((nid, c))
        else:
            labels[nid] = str(node)
            x = leaf_x['val']
            positions[nid] = (x, -depth)
            leaf_x['val'] += 1
        return nid

    traverse(nltk_tree, 0)
    return positions, labels, edges

def plot_nltk_tree_inline(nltk_tree, title=None, figsize=(10,4)):
    positions, labels, edges = _assign_positions(nltk_tree)
    xs = [p[0] for p in positions.values()]
    fig, ax = plt.subplots(figsize=figsize)
    for p,c in edges:
        x1,y1 = positions[p]; x2,y2 = positions[c]
        ax.plot([x1,x2],[y1,y2], color="black", linewidth=0.8)
    for nid,(x,y) in positions.items():
        lab = labels[nid]
        ax.text(x, y, lab, ha='center', va='center', fontsize=9,
                bbox=dict(boxstyle='round', fc='white', ec='black', lw=0.6))
    ax.set_axis_off()
    if title:
        ax.set_title(title, fontsize=11, weight='bold')
    ax.set_xlim(min(xs)-0.5, max(xs)+0.5)
    plt.show()


# Toy grammar

toy_grammar_text = r"""
S -> NP VP | VP | WH NP VP | Quote S Quote | S END
NP -> Nominal | DT Nominal | DT NP | Adj NP | Adv NP | PP NP | CD NP | Mod NP | PRP_DOLLAR NP | PDT DT | NP POS | DT Adj NP | NP Adj | NP PP | Adj PP
VP -> MD Verb | Verb | VP NP | NP VP | VP Adv | VP PRP_DOLLAR NP Adv | TO VP | VP UH | VP RP | VP TO | Adv NP | DT VP | VP Mod VP | VP VP | VP PP | VP PRP_DOLLAR | WH VP | Verb NP
PP -> IN | IN NP | IN VP | IN DT | IN CD | PP NP
Verb -> VB | VBD | VBG | VBN | VBP | VBZ
Noun -> NN | NNP | NNPS | NNS | PRP | WP
Adj -> JJ | JJR | JJS | Adj Mod Adj
Adv -> RB | RBR | RBS | WRB
Mod -> CC Mod | MD | CC MD | CC | CC NP
WH -> WP | WDT
Nominal -> Noun | Nominal Noun
Quote -> Quote1 | Quote2
END -> Comma | Dot | Colon | CD

Dot -> '.'
Colon -> ':'
Comma -> ','
Dollar -> '$'
LRB -> '-LRB-'
RRB -> '-RRB-'
CC -> 'CC'
CD -> 'CD'
DT -> 'DT'
EX -> 'EX'
FW -> 'FW'
GW -> 'GW'
HYPH -> 'HYPH'
IN -> 'IN'
JJ -> 'JJ'
JJR -> 'JJR'
JJS -> 'JJS'
MD -> 'MD'
NN -> 'NN'
NNP -> 'NNP'
NNPS -> 'NNPS'
NNS -> 'NNS'
PDT -> 'PDT'
POS -> 'POS'
PRP -> 'PRP'
PRP_DOLLAR -> 'PRP$'
RB -> 'RB'
RBR -> 'RBR'
RBS -> 'RBS'
RP -> 'RP'
TO -> 'TO'
UH -> 'UH'
VB -> 'VB'
VBD -> 'VBD'
VBG -> 'VBG'
VBN -> 'VBN'
VBP -> 'VBP'
VBZ -> 'VBZ'
WDT -> 'WDT'
WP -> 'WP'
WRB -> 'WRB'
Quote1 -> '``'
Quote2 -> "''"
"""

# Load grammar
try:
    GRAMMAR = CFG.fromstring(toy_grammar_text)
except Exception as ex:
    print("ERROR: Could not load grammar. Details:")
    raise

PARSER = ChartParser(GRAMMAR)

# Parsing helpers

def parse_pos_sequence(pos_sequence, max_trees=3):
    """
    pos_sequence: string of POS tokens separated by spaces, e.g. "PRP VBD DT NN ."
    Returns: (is_valid (bool), list_of_trees (nltk.Tree objects))
    """
    tokens = pos_sequence.strip().split()
    trees = []
    try:
        trees = list(PARSER.parse(tokens))
    except ValueError as e:
        # e.g., grammar coverage problems
        # return empty trees
        trees = []
    return (len(trees) > 0, trees[:max_trees])

# map penn tags -> grammar terminals
def simplify_penn_tag(tag, word=None):
    """
    Convert a Penn tag (or token) into a grammar terminal token.
    If token is punctuation (like '.' or ','), return the punctuation itself.
    """
    # if token (word) is punctuation, return the punctuation symbol
    if word is not None and word in {'.', ',', ':', '$', "''", "``", "-LRB-", "-RRB-"}:
        return word
    if tag is None:
        return tag

    # Exact tag cases
    if tag == "PRP$":
        return "PRP$"
    if tag.startswith("NNP"):
        return "NNP"
    if tag.startswith("NNPS"):
        return "NNPS"
    if tag.startswith("NN"):
        return "NN"
    if tag.startswith("VBZ"):
        return "VBZ"
    if tag.startswith("VBP"):
        return "VBP"
    if tag.startswith("VBD"):
        return "VBD"
    if tag.startswith("VBG"):
        return "VBG"
    if tag.startswith("VBN"):
        return "VBN"
    if tag.startswith("VB"):
        return "VB"
    if tag.startswith("PRP"):
        return "PRP"
    if tag.startswith("RB"):
        return "RB"
    if tag.startswith("JJ"):
        return "JJ"
    if tag.startswith("DT"):
        return "DT"
    if tag.startswith("IN"):
        return "IN"
    if tag == "TO":
        return "TO"
    if tag == "CC":
        return "CC"
    if tag == "CD":
        return "CD"
    if tag == "PDT":
        return "PDT"
    if tag == "POS":
        return "POS"
    if tag == "UH":
        return "UH"
    if tag == "WP":
        return "WP"
    if tag == "WDT":
        return "WDT"
    if tag == "WRB":
        return "WRB"
    # fallback: return tag itself (may or may not be in grammar)
    return tag


# Batch evaluation on dataset (if present)

DATA_PATH = "/content/train.tsv"   # update if needed
results = None
if os.path.exists(DATA_PATH):
    try:
        print("Dataset found at", DATA_PATH, " — loading and running batch CFG checks.\n")
        df = pd.read_csv(DATA_PATH, sep="\t", quoting=3, dtype=str)  # quoting=3 -> QUOTE_NONE to be permissive
        # ensure required cols
        if 'pos' not in df.columns:
            raise ValueError("Dataset does not contain a 'pos' column. This code expects POS sequences in a column named 'pos'.")
        # Prepare output columns
        df['pred'] = -1  # 0 = valid (grammar accepts), 1 = invalid (grammar rejects)
        df['parse_examples'] = None
        df['error_reason'] = None

        total = len(df)
        start = time.time()
        for idx, row in df.iterrows():
            pos_seq = str(row['pos']).strip()
            valid, trees = parse_pos_sequence(pos_seq, max_trees=2)
            df.at[idx, 'pred'] = 0 if valid else 1
            if valid:
                df.at[idx, 'parse_examples'] = [t.pformat(margin=60) for t in trees]
            else:
                df.at[idx, 'parse_examples'] = []
                df.at[idx, 'error_reason'] = "No parse"
        elapsed = time.time() - start

        # Show brief summary
        display(Markdown("## Batch Evaluation Results"))
        display(Markdown(f"- Total sentences: **{total}**"))
        display(Markdown(f"- Time taken: **{elapsed:.2f}s**"))
        display(Markdown(f"- Valid (pred=0): **{(df['pred']==0).sum()}**, Invalid (pred=1): **{(df['pred']==1).sum()}**"))

        results = df
    except Exception as e:
        print("Error while loading or running batch on dataset:", e)
        results = None
else:
    display(Markdown("## Dataset not found — running fallback demo examples"))
    demo = [
        ("It's very confusing without the right signs .", "PRP VBZ RB JJ IN DT JJ NNS ."),
        ("We are restricted in doing nearly everything .", "PRP VBP JJ IN VBG RB NN ."),
        ("I received your letter yesterday .", "PRP VBD PRP$ NN RB ."),
        ("John saw the man with the telescope .", "NNP VBD DT NN IN DT NN ."),
        ("I made a big mistake by trusting him .", "PRP VBD DT JJ NN IN VBG PRP ."),
    ]
    for sent, pos_seq in demo:
        display(Markdown(f"**Sentence:** {sent}"))
        display(Markdown(f"- POS sequence: `{pos_seq}`"))
        valid, trees = parse_pos_sequence(pos_seq, max_trees=2)
        if valid:
            display(Markdown("- **Parse:** VALID "))
            for i,t in enumerate(trees,1):
                display(Markdown(f"**Parse {i}** (bracketed):"))
                print(t)
                plot_nltk_tree_inline(t, title=f"Demo parse {i}")
        else:
            display(Markdown("- **Parse:** INVALID  (no parse with toy grammar)"))


# Interactive loop (dual-mode)

print("\n=== Interactive check ===")
print("Choose input mode:")
print("  1 = Paste a POS-tag sequence (e.g. PRP VBZ RB JJ IN DT JJ NNS .)")
print("  2 = Paste a raw sentence (will be tokenized & POS-tagged automatically)")
print("Type 'quit' at any prompt to exit.\n")

def is_probably_pos_sequence(s):
    # heuristic: mostly uppercase tokens or punctuation tokens
    toks = s.strip().split()
    if not toks:
        return False
    # acceptable token examples: PRP, VBD, ., ',', 'PRP$'
    for t in toks:
        # allow punctuation tokens exactly ., :, , , `` , ''
        if t in {'.', ',', ':', '$', "''", "``", "-LRB-", "-RRB-"}:
            continue
        # allow uppercase tokens that contain letters/digits and maybe $
        if t.isupper() or ('$' in t and t.replace('$','').isupper()):
            continue
        return False
    return True

while True:
    choice = input("Select mode (1 = POS seq, 2 = raw sentence, quit = exit): ").strip().lower()
    if choice in ('quit','q','exit'):
        print("Exiting interactive check.")
        break
    if choice not in ('1','2'):
        print("Please enter 1 or 2 (or 'quit').")
        continue

    if choice == '1':
        # POS sequence path
        user_input = input("\nPaste POS sequence (space-separated): ").strip()
        if user_input.lower() in ('quit','exit'):
            print("Returning to mode selection.")
            continue
        if not user_input:
            print("Empty input — try again.")
            continue

        # validate heuristic
        if not is_probably_pos_sequence(user_input):
            print("Warning: input doesn't look like an uppercase POS sequence. Still attempting to parse.")
        valid, trees = parse_pos_sequence(user_input, max_trees=3)
        print("POS sequence parsed:", user_input)
        if valid:
            print("Result: VALID  — toy grammar accepts this POS sequence.\n")
            for i,t in enumerate(trees,1):
                print(f"--- Parse {i} ---")
                print(t)
                try:
                    plot_nltk_tree_inline(t, title=f"Parse {i}")
                except Exception as e:
                    print("Plotting failed:", e)
        else:
            print("Result: INVALID  (no parse found for this POS sequence).")
            print("Tip: check that POS tokens exactly match grammar terminals (e.g., PRP, PRP$, VBD, ., etc.)")

    else:
        # Raw sentence path: tokenize + pos_tag -> simplify tags -> parse
        sent = input("\nPaste raw sentence: ").strip()
        if sent.lower() in ('quit','exit'):
            print("Returning to mode selection.")
            continue
        if not sent:
            print("Empty input — try again.")
            continue

        # Tokenize & POS-tag
        tokens = nltk.word_tokenize(sent)
        tagged = nltk.pos_tag(tokens)
        # Convert tags to simplified grammar tokens (and keep punctuation tokens like '.' as themselves)
        simplified_tags = []
        for word, tag in tagged:
            # punctuation as token: use the punctuation itself
            if word in {'.', ',', ':', '$', "''", "``", "-LRB-", "-RRB-"}:
                simplified_tags.append(word)
            else:
                simplified_tags.append(simplify_penn_tag(tag, word))

        pos_seq = " ".join(simplified_tags)
        print("\nAuto POS-tagged sequence:", pos_seq)
        valid, trees = parse_pos_sequence(pos_seq, max_trees=3)
        if valid:
            print("Result: VALID  — toy grammar accepts the POS sequence derived from your sentence.\n")
            for i,t in enumerate(trees,1):
                print(f"--- Parse {i} (bracketed) ---")
                print(t)
                try:
                    plot_nltk_tree_inline(t, title=f"Parse {i}")
                except Exception as e:
                    print("Plotting failed:", e)
        else:
            print("Result: INVALID  — no parse found for the POS sequence derived from your sentence.")
            print("You can try:")
            print(" - supplying the POS sequence manually (mode 1)")
            print(" - checking tag mapping for unusual tokens (names, contractions, punctuation)")
            # optionally show the generated pos_seq so user can copy and edit
            print("Derived POS sequence (copy to mode 1 to debug):")
            print(pos_seq)